syntax = "proto3";

package flyteidl2.dataproxy;

import "buf/validate/validate.proto";
import "google/api/annotations.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";
import "protoc-gen-openapiv2/options/annotations.proto";

option go_package = "github.com/flyteorg/flyte/v2/gen/go/flyteidl2/dataproxy";

// DataProxyService provides an interface for managing data uploads and downloads.
service DataProxyService {
  // CreateUploadLocation generates a signed URL for uploading data to the configured storage backend.
  rpc CreateUploadLocation(CreateUploadLocationRequest) returns (CreateUploadLocationResponse) {
    option (google.api.http) = {
      post: "/api/v1/dataproxy/artifact_urn"
      body: "*"
      additional_bindings: {
        post: "/api/v1/org/dataproxy/artifact_urn"
        body: "*"
      }
    };
    option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_operation) = {description: "Creates a write-only http location that is accessible for tasks at runtime."};
  }
}

// CreateUploadLocationRequest specifies the request for the CreateUploadLocation API.
// The data proxy service will generate a storage location with server-side configured prefixes.
// The generated path follows one of these patterns:
//   - project/domain/(deterministic hash of content_md5)/filename (if filename is present); OR
//   - project/domain/filename_root/filename (if filename_root and filename are present).
message CreateUploadLocationRequest {
  // Project to create the upload location for.
  // +required
  string project = 1 [(buf.validate.field).string.min_len = 1];

  // Domain to create the upload location for.
  // +required
  string domain = 2 [(buf.validate.field).string.min_len = 1];

  // Filename specifies the desired suffix for the generated location. E.g. `file.py` or `pre/fix/file.zip`.
  // +optional. By default, the service generates a consistent name based on the default filename length provided in the global config..
  string filename = 3;

  // ExpiresIn defines the requested expiration duration for the generated URL. The request will be rejected if this
  // exceeds the platform's configured maximum.
  // +optional. The default value comes from the global config.
  google.protobuf.Duration expires_in = 4;

  // ContentMD5 restricts the upload location to the specific MD5 provided. The MD5 hash will also appear in the
  // generated path for verification.
  // +required
  bytes content_md5 = 5 [(buf.validate.field).bytes.len = 16];

  // FilenameRoot, if present, will be used instead of the MD5 hash in the path. When combined with filename,
  // this makes the upload location deterministic. The native URL will still be prefixed by the upload location prefix
  // configured in the data proxy. This option is useful when uploading multiple related files.
  // +optional
  string filename_root = 6;

  // If true, the data proxy will add content_md5 to the Signed URL requirements,
  // forcing clients to send this checksum with the object.
  // This is required to enforce data integrity on backends like GCP, ensuring that
  // the uploaded file matches the hash.
  bool add_content_md5_metadata = 7;

  // Org is the organization key applied to the resource.
  // +optional
  string org = 8;

  // ContentLength specifies the size of the content to be uploaded in bytes.
  // This is validated against the platform's maximum upload size if provided.
  // +optional
  int64 content_length = 9;
}

// CreateUploadLocationResponse specifies the response for the CreateUploadLocation API.
message CreateUploadLocationResponse {
  // SignedUrl is the URL to use for uploading content (e.g. https://my-bucket.s3.amazonaws.com/randomstring/suffix.tar?X-...).
  string signed_url = 1;

  // NativeUrl is the URL in the format of the configured storage provider (e.g. s3://my-bucket/randomstring/suffix.tar).
  string native_url = 2;

  // ExpiresAt defines when the signed URL will expire.
  google.protobuf.Timestamp expires_at = 3;

  // Headers are generated by the data proxy for the client. Clients must include these headers in the upload request.
  map<string, string> headers = 4;
}
