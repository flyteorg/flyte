// @generated by protoc-gen-es v2.2.5 with parameter "target=ts,import_extension=.ts"
// @generated from file flyteidl2/plugins/pytorch.proto (package flyteidl2.plugins, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file flyteidl2/plugins/pytorch.proto.
 */
export const file_flyteidl2_plugins_pytorch: GenFile = /*@__PURE__*/
  fileDesc("Ch9mbHl0ZWlkbDIvcGx1Z2lucy9weXRvcmNoLnByb3RvEhFmbHl0ZWlkbDIucGx1Z2lucyJ/Cg1FbGFzdGljQ29uZmlnEhQKDHJkenZfYmFja2VuZBgBIAEoCRIUCgxtaW5fcmVwbGljYXMYAiABKAUSFAoMbWF4X3JlcGxpY2FzGAMgASgFEhYKDm5wcm9jX3Blcl9ub2RlGAQgASgFEhQKDG1heF9yZXN0YXJ0cxgFIAEoBSJrCh5EaXN0cmlidXRlZFB5VG9yY2hUcmFpbmluZ1Rhc2sSDwoHd29ya2VycxgBIAEoBRI4Cg5lbGFzdGljX2NvbmZpZxgCIAEoCzIgLmZseXRlaWRsMi5wbHVnaW5zLkVsYXN0aWNDb25maWdCwwEKFWNvbS5mbHl0ZWlkbDIucGx1Z2luc0IMUHl0b3JjaFByb3RvSAJQAVo1Z2l0aHViLmNvbS9mbHl0ZW9yZy9mbHl0ZS92Mi9nZW4vZ28vZmx5dGVpZGwyL3BsdWdpbnOiAgNGUFiqAhFGbHl0ZWlkbDIuUGx1Z2luc8oCEUZseXRlaWRsMlxQbHVnaW5z4gIdRmx5dGVpZGwyXFBsdWdpbnNcR1BCTWV0YWRhdGHqAhJGbHl0ZWlkbDI6OlBsdWdpbnNiBnByb3RvMw");

/**
 * Custom proto for torch elastic config for distributed training using
 * https://github.com/kubeflow/trainer/blob/e31d11faa9f6ce5111b60c01079d39295589e0ef/pkg/apis/kubeflow.org/v1/pytorch_types.go#L98
 *
 * @generated from message flyteidl2.plugins.ElasticConfig
 */
export type ElasticConfig = Message<"flyteidl2.plugins.ElasticConfig"> & {
  /**
   * @generated from field: string rdzv_backend = 1;
   */
  rdzvBackend: string;

  /**
   * @generated from field: int32 min_replicas = 2;
   */
  minReplicas: number;

  /**
   * @generated from field: int32 max_replicas = 3;
   */
  maxReplicas: number;

  /**
   * @generated from field: int32 nproc_per_node = 4;
   */
  nprocPerNode: number;

  /**
   * @generated from field: int32 max_restarts = 5;
   */
  maxRestarts: number;
};

/**
 * Describes the message flyteidl2.plugins.ElasticConfig.
 * Use `create(ElasticConfigSchema)` to create a new message.
 */
export const ElasticConfigSchema: GenMessage<ElasticConfig> = /*@__PURE__*/
  messageDesc(file_flyteidl2_plugins_pytorch, 0);

/**
 * Custom proto for plugin that enables distributed training using https://github.com/kubeflow/trainer
 *
 * @generated from message flyteidl2.plugins.DistributedPyTorchTrainingTask
 */
export type DistributedPyTorchTrainingTask = Message<"flyteidl2.plugins.DistributedPyTorchTrainingTask"> & {
  /**
   * number of worker replicas spawned in the cluster for this job
   *
   * @generated from field: int32 workers = 1;
   */
  workers: number;

  /**
   * config for an elastic pytorch job
   *
   * @generated from field: flyteidl2.plugins.ElasticConfig elastic_config = 2;
   */
  elasticConfig?: ElasticConfig;
};

/**
 * Describes the message flyteidl2.plugins.DistributedPyTorchTrainingTask.
 * Use `create(DistributedPyTorchTrainingTaskSchema)` to create a new message.
 */
export const DistributedPyTorchTrainingTaskSchema: GenMessage<DistributedPyTorchTrainingTask> = /*@__PURE__*/
  messageDesc(file_flyteidl2_plugins_pytorch, 1);

