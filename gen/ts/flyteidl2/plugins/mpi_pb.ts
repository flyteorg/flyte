// @generated by protoc-gen-es v2.2.5 with parameter "target=ts,import_extension=.ts"
// @generated from file flyteidl2/plugins/mpi.proto (package flyteidl2.plugins, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file flyteidl2/plugins/mpi.proto.
 */
export const file_flyteidl2_plugins_mpi: GenFile = /*@__PURE__*/
  fileDesc("ChtmbHl0ZWlkbDIvcGx1Z2lucy9tcGkucHJvdG8SEWZseXRlaWRsMi5wbHVnaW5zIl8KGkRpc3RyaWJ1dGVkTVBJVHJhaW5pbmdUYXNrEhMKC251bV93b3JrZXJzGAEgASgFEh0KFW51bV9sYXVuY2hlcl9yZXBsaWNhcxgCIAEoBRINCgVzbG90cxgDIAEoBUK/AQoVY29tLmZseXRlaWRsMi5wbHVnaW5zQghNcGlQcm90b0gCUAFaNWdpdGh1Yi5jb20vZmx5dGVvcmcvZmx5dGUvdjIvZ2VuL2dvL2ZseXRlaWRsMi9wbHVnaW5zogIDRlBYqgIRRmx5dGVpZGwyLlBsdWdpbnPKAhFGbHl0ZWlkbDJcUGx1Z2luc+ICHUZseXRlaWRsMlxQbHVnaW5zXEdQQk1ldGFkYXRh6gISRmx5dGVpZGwyOjpQbHVnaW5zYgZwcm90bzM");

/**
 * MPI operator proposal https://github.com/kubeflow/community/blob/master/proposals/mpi-operator-proposal.md
 * Custom proto for plugin that enables distributed training using https://github.com/kubeflow/mpi-operator
 *
 * @generated from message flyteidl2.plugins.DistributedMPITrainingTask
 */
export type DistributedMPITrainingTask = Message<"flyteidl2.plugins.DistributedMPITrainingTask"> & {
  /**
   * number of worker spawned in the cluster for this job
   *
   * @generated from field: int32 num_workers = 1;
   */
  numWorkers: number;

  /**
   * number of launcher replicas spawned in the cluster for this job
   * The launcher pod invokes mpirun and communicates with worker pods through MPI.
   *
   * @generated from field: int32 num_launcher_replicas = 2;
   */
  numLauncherReplicas: number;

  /**
   * number of slots per worker used in hostfile.
   * The available slots (GPUs) in each pod.
   *
   * @generated from field: int32 slots = 3;
   */
  slots: number;
};

/**
 * Describes the message flyteidl2.plugins.DistributedMPITrainingTask.
 * Use `create(DistributedMPITrainingTaskSchema)` to create a new message.
 */
export const DistributedMPITrainingTaskSchema: GenMessage<DistributedMPITrainingTask> = /*@__PURE__*/
  messageDesc(file_flyteidl2_plugins_mpi, 0);

