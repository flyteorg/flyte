// Code generated by protoc-gen-validate. DO NOT EDIT.
// source: flyteidl2/plugins/kubeflow/pytorch.proto

package kubeflow

import (
	"bytes"
	"errors"
	"fmt"
	"net"
	"net/mail"
	"net/url"
	"regexp"
	"sort"
	"strings"
	"time"
	"unicode/utf8"

	"google.golang.org/protobuf/types/known/anypb"

	plugins "github.com/flyteorg/flyte/v2/gen/go/flyteidl2/plugins"
)

// ensure the imports are used
var (
	_ = bytes.MinRead
	_ = errors.New("")
	_ = fmt.Print
	_ = utf8.UTFMax
	_ = (*regexp.Regexp)(nil)
	_ = (*strings.Reader)(nil)
	_ = net.IPv4len
	_ = time.Duration(0)
	_ = (*url.URL)(nil)
	_ = (*mail.Address)(nil)
	_ = anypb.Any{}
	_ = sort.Sort

	_ = plugins.RestartPolicy(0)
)

// Validate checks the field values on ElasticConfig with the rules defined in
// the proto definition for this message. If any rules are violated, the first
// error encountered is returned, or nil if there are no violations.
func (m *ElasticConfig) Validate() error {
	return m.validate(false)
}

// ValidateAll checks the field values on ElasticConfig with the rules defined
// in the proto definition for this message. If any rules are violated, the
// result is a list of violation errors wrapped in ElasticConfigMultiError, or
// nil if none found.
func (m *ElasticConfig) ValidateAll() error {
	return m.validate(true)
}

func (m *ElasticConfig) validate(all bool) error {
	if m == nil {
		return nil
	}

	var errors []error

	// no validation rules for RdzvBackend

	// no validation rules for MinReplicas

	// no validation rules for MaxReplicas

	// no validation rules for NprocPerNode

	// no validation rules for MaxRestarts

	if len(errors) > 0 {
		return ElasticConfigMultiError(errors)
	}

	return nil
}

// ElasticConfigMultiError is an error wrapping multiple validation errors
// returned by ElasticConfig.ValidateAll() if the designated constraints
// aren't met.
type ElasticConfigMultiError []error

// Error returns a concatenation of all the error messages it wraps.
func (m ElasticConfigMultiError) Error() string {
	msgs := make([]string, 0, len(m))
	for _, err := range m {
		msgs = append(msgs, err.Error())
	}
	return strings.Join(msgs, "; ")
}

// AllErrors returns a list of validation violation errors.
func (m ElasticConfigMultiError) AllErrors() []error { return m }

// ElasticConfigValidationError is the validation error returned by
// ElasticConfig.Validate if the designated constraints aren't met.
type ElasticConfigValidationError struct {
	field  string
	reason string
	cause  error
	key    bool
}

// Field function returns field value.
func (e ElasticConfigValidationError) Field() string { return e.field }

// Reason function returns reason value.
func (e ElasticConfigValidationError) Reason() string { return e.reason }

// Cause function returns cause value.
func (e ElasticConfigValidationError) Cause() error { return e.cause }

// Key function returns key value.
func (e ElasticConfigValidationError) Key() bool { return e.key }

// ErrorName returns error name.
func (e ElasticConfigValidationError) ErrorName() string { return "ElasticConfigValidationError" }

// Error satisfies the builtin error interface
func (e ElasticConfigValidationError) Error() string {
	cause := ""
	if e.cause != nil {
		cause = fmt.Sprintf(" | caused by: %v", e.cause)
	}

	key := ""
	if e.key {
		key = "key for "
	}

	return fmt.Sprintf(
		"invalid %sElasticConfig.%s: %s%s",
		key,
		e.field,
		e.reason,
		cause)
}

var _ error = ElasticConfigValidationError{}

var _ interface {
	Field() string
	Reason() string
	Key() bool
	Cause() error
	ErrorName() string
} = ElasticConfigValidationError{}

// Validate checks the field values on DistributedPyTorchTrainingTask with the
// rules defined in the proto definition for this message. If any rules are
// violated, the first error encountered is returned, or nil if there are no violations.
func (m *DistributedPyTorchTrainingTask) Validate() error {
	return m.validate(false)
}

// ValidateAll checks the field values on DistributedPyTorchTrainingTask with
// the rules defined in the proto definition for this message. If any rules
// are violated, the result is a list of violation errors wrapped in
// DistributedPyTorchTrainingTaskMultiError, or nil if none found.
func (m *DistributedPyTorchTrainingTask) ValidateAll() error {
	return m.validate(true)
}

func (m *DistributedPyTorchTrainingTask) validate(all bool) error {
	if m == nil {
		return nil
	}

	var errors []error

	if all {
		switch v := interface{}(m.GetWorkerReplicas()).(type) {
		case interface{ ValidateAll() error }:
			if err := v.ValidateAll(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "WorkerReplicas",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		case interface{ Validate() error }:
			if err := v.Validate(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "WorkerReplicas",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		}
	} else if v, ok := interface{}(m.GetWorkerReplicas()).(interface{ Validate() error }); ok {
		if err := v.Validate(); err != nil {
			return DistributedPyTorchTrainingTaskValidationError{
				field:  "WorkerReplicas",
				reason: "embedded message failed validation",
				cause:  err,
			}
		}
	}

	if all {
		switch v := interface{}(m.GetMasterReplicas()).(type) {
		case interface{ ValidateAll() error }:
			if err := v.ValidateAll(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "MasterReplicas",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		case interface{ Validate() error }:
			if err := v.Validate(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "MasterReplicas",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		}
	} else if v, ok := interface{}(m.GetMasterReplicas()).(interface{ Validate() error }); ok {
		if err := v.Validate(); err != nil {
			return DistributedPyTorchTrainingTaskValidationError{
				field:  "MasterReplicas",
				reason: "embedded message failed validation",
				cause:  err,
			}
		}
	}

	if all {
		switch v := interface{}(m.GetRunPolicy()).(type) {
		case interface{ ValidateAll() error }:
			if err := v.ValidateAll(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "RunPolicy",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		case interface{ Validate() error }:
			if err := v.Validate(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "RunPolicy",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		}
	} else if v, ok := interface{}(m.GetRunPolicy()).(interface{ Validate() error }); ok {
		if err := v.Validate(); err != nil {
			return DistributedPyTorchTrainingTaskValidationError{
				field:  "RunPolicy",
				reason: "embedded message failed validation",
				cause:  err,
			}
		}
	}

	if all {
		switch v := interface{}(m.GetElasticConfig()).(type) {
		case interface{ ValidateAll() error }:
			if err := v.ValidateAll(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "ElasticConfig",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		case interface{ Validate() error }:
			if err := v.Validate(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingTaskValidationError{
					field:  "ElasticConfig",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		}
	} else if v, ok := interface{}(m.GetElasticConfig()).(interface{ Validate() error }); ok {
		if err := v.Validate(); err != nil {
			return DistributedPyTorchTrainingTaskValidationError{
				field:  "ElasticConfig",
				reason: "embedded message failed validation",
				cause:  err,
			}
		}
	}

	if len(errors) > 0 {
		return DistributedPyTorchTrainingTaskMultiError(errors)
	}

	return nil
}

// DistributedPyTorchTrainingTaskMultiError is an error wrapping multiple
// validation errors returned by DistributedPyTorchTrainingTask.ValidateAll()
// if the designated constraints aren't met.
type DistributedPyTorchTrainingTaskMultiError []error

// Error returns a concatenation of all the error messages it wraps.
func (m DistributedPyTorchTrainingTaskMultiError) Error() string {
	msgs := make([]string, 0, len(m))
	for _, err := range m {
		msgs = append(msgs, err.Error())
	}
	return strings.Join(msgs, "; ")
}

// AllErrors returns a list of validation violation errors.
func (m DistributedPyTorchTrainingTaskMultiError) AllErrors() []error { return m }

// DistributedPyTorchTrainingTaskValidationError is the validation error
// returned by DistributedPyTorchTrainingTask.Validate if the designated
// constraints aren't met.
type DistributedPyTorchTrainingTaskValidationError struct {
	field  string
	reason string
	cause  error
	key    bool
}

// Field function returns field value.
func (e DistributedPyTorchTrainingTaskValidationError) Field() string { return e.field }

// Reason function returns reason value.
func (e DistributedPyTorchTrainingTaskValidationError) Reason() string { return e.reason }

// Cause function returns cause value.
func (e DistributedPyTorchTrainingTaskValidationError) Cause() error { return e.cause }

// Key function returns key value.
func (e DistributedPyTorchTrainingTaskValidationError) Key() bool { return e.key }

// ErrorName returns error name.
func (e DistributedPyTorchTrainingTaskValidationError) ErrorName() string {
	return "DistributedPyTorchTrainingTaskValidationError"
}

// Error satisfies the builtin error interface
func (e DistributedPyTorchTrainingTaskValidationError) Error() string {
	cause := ""
	if e.cause != nil {
		cause = fmt.Sprintf(" | caused by: %v", e.cause)
	}

	key := ""
	if e.key {
		key = "key for "
	}

	return fmt.Sprintf(
		"invalid %sDistributedPyTorchTrainingTask.%s: %s%s",
		key,
		e.field,
		e.reason,
		cause)
}

var _ error = DistributedPyTorchTrainingTaskValidationError{}

var _ interface {
	Field() string
	Reason() string
	Key() bool
	Cause() error
	ErrorName() string
} = DistributedPyTorchTrainingTaskValidationError{}

// Validate checks the field values on DistributedPyTorchTrainingReplicaSpec
// with the rules defined in the proto definition for this message. If any
// rules are violated, the first error encountered is returned, or nil if
// there are no violations.
func (m *DistributedPyTorchTrainingReplicaSpec) Validate() error {
	return m.validate(false)
}

// ValidateAll checks the field values on DistributedPyTorchTrainingReplicaSpec
// with the rules defined in the proto definition for this message. If any
// rules are violated, the result is a list of violation errors wrapped in
// DistributedPyTorchTrainingReplicaSpecMultiError, or nil if none found.
func (m *DistributedPyTorchTrainingReplicaSpec) ValidateAll() error {
	return m.validate(true)
}

func (m *DistributedPyTorchTrainingReplicaSpec) validate(all bool) error {
	if m == nil {
		return nil
	}

	var errors []error

	// no validation rules for Replicas

	// no validation rules for Image

	if all {
		switch v := interface{}(m.GetResources()).(type) {
		case interface{ ValidateAll() error }:
			if err := v.ValidateAll(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingReplicaSpecValidationError{
					field:  "Resources",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		case interface{ Validate() error }:
			if err := v.Validate(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingReplicaSpecValidationError{
					field:  "Resources",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		}
	} else if v, ok := interface{}(m.GetResources()).(interface{ Validate() error }); ok {
		if err := v.Validate(); err != nil {
			return DistributedPyTorchTrainingReplicaSpecValidationError{
				field:  "Resources",
				reason: "embedded message failed validation",
				cause:  err,
			}
		}
	}

	// no validation rules for RestartPolicy

	if all {
		switch v := interface{}(m.GetCommon()).(type) {
		case interface{ ValidateAll() error }:
			if err := v.ValidateAll(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingReplicaSpecValidationError{
					field:  "Common",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		case interface{ Validate() error }:
			if err := v.Validate(); err != nil {
				errors = append(errors, DistributedPyTorchTrainingReplicaSpecValidationError{
					field:  "Common",
					reason: "embedded message failed validation",
					cause:  err,
				})
			}
		}
	} else if v, ok := interface{}(m.GetCommon()).(interface{ Validate() error }); ok {
		if err := v.Validate(); err != nil {
			return DistributedPyTorchTrainingReplicaSpecValidationError{
				field:  "Common",
				reason: "embedded message failed validation",
				cause:  err,
			}
		}
	}

	if len(errors) > 0 {
		return DistributedPyTorchTrainingReplicaSpecMultiError(errors)
	}

	return nil
}

// DistributedPyTorchTrainingReplicaSpecMultiError is an error wrapping
// multiple validation errors returned by
// DistributedPyTorchTrainingReplicaSpec.ValidateAll() if the designated
// constraints aren't met.
type DistributedPyTorchTrainingReplicaSpecMultiError []error

// Error returns a concatenation of all the error messages it wraps.
func (m DistributedPyTorchTrainingReplicaSpecMultiError) Error() string {
	msgs := make([]string, 0, len(m))
	for _, err := range m {
		msgs = append(msgs, err.Error())
	}
	return strings.Join(msgs, "; ")
}

// AllErrors returns a list of validation violation errors.
func (m DistributedPyTorchTrainingReplicaSpecMultiError) AllErrors() []error { return m }

// DistributedPyTorchTrainingReplicaSpecValidationError is the validation error
// returned by DistributedPyTorchTrainingReplicaSpec.Validate if the
// designated constraints aren't met.
type DistributedPyTorchTrainingReplicaSpecValidationError struct {
	field  string
	reason string
	cause  error
	key    bool
}

// Field function returns field value.
func (e DistributedPyTorchTrainingReplicaSpecValidationError) Field() string { return e.field }

// Reason function returns reason value.
func (e DistributedPyTorchTrainingReplicaSpecValidationError) Reason() string { return e.reason }

// Cause function returns cause value.
func (e DistributedPyTorchTrainingReplicaSpecValidationError) Cause() error { return e.cause }

// Key function returns key value.
func (e DistributedPyTorchTrainingReplicaSpecValidationError) Key() bool { return e.key }

// ErrorName returns error name.
func (e DistributedPyTorchTrainingReplicaSpecValidationError) ErrorName() string {
	return "DistributedPyTorchTrainingReplicaSpecValidationError"
}

// Error satisfies the builtin error interface
func (e DistributedPyTorchTrainingReplicaSpecValidationError) Error() string {
	cause := ""
	if e.cause != nil {
		cause = fmt.Sprintf(" | caused by: %v", e.cause)
	}

	key := ""
	if e.key {
		key = "key for "
	}

	return fmt.Sprintf(
		"invalid %sDistributedPyTorchTrainingReplicaSpec.%s: %s%s",
		key,
		e.field,
		e.reason,
		cause)
}

var _ error = DistributedPyTorchTrainingReplicaSpecValidationError{}

var _ interface {
	Field() string
	Reason() string
	Key() bool
	Cause() error
	ErrorName() string
} = DistributedPyTorchTrainingReplicaSpecValidationError{}
