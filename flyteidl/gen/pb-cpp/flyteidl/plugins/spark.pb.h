// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: flyteidl/plugins/spark.proto

#ifndef PROTOBUF_INCLUDED_flyteidl_2fplugins_2fspark_2eproto
#define PROTOBUF_INCLUDED_flyteidl_2fplugins_2fspark_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3007000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3007000 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/map.h>  // IWYU pragma: export
#include <google/protobuf/map_entry.h>
#include <google/protobuf/map_field_inl.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include <google/protobuf/struct.pb.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_flyteidl_2fplugins_2fspark_2eproto

// Internal implementation detail -- do not use these members.
struct TableStruct_flyteidl_2fplugins_2fspark_2eproto {
  static const ::google::protobuf::internal::ParseTableField entries[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::google::protobuf::internal::ParseTable schema[4]
    PROTOBUF_SECTION_VARIABLE(protodesc_cold);
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors_flyteidl_2fplugins_2fspark_2eproto();
namespace flyteidl {
namespace plugins {
class SparkApplication;
class SparkApplicationDefaultTypeInternal;
extern SparkApplicationDefaultTypeInternal _SparkApplication_default_instance_;
class SparkJob;
class SparkJobDefaultTypeInternal;
extern SparkJobDefaultTypeInternal _SparkJob_default_instance_;
class SparkJob_HadoopConfEntry_DoNotUse;
class SparkJob_HadoopConfEntry_DoNotUseDefaultTypeInternal;
extern SparkJob_HadoopConfEntry_DoNotUseDefaultTypeInternal _SparkJob_HadoopConfEntry_DoNotUse_default_instance_;
class SparkJob_SparkConfEntry_DoNotUse;
class SparkJob_SparkConfEntry_DoNotUseDefaultTypeInternal;
extern SparkJob_SparkConfEntry_DoNotUseDefaultTypeInternal _SparkJob_SparkConfEntry_DoNotUse_default_instance_;
}  // namespace plugins
}  // namespace flyteidl
namespace google {
namespace protobuf {
template<> ::flyteidl::plugins::SparkApplication* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkApplication>(Arena*);
template<> ::flyteidl::plugins::SparkJob* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkJob>(Arena*);
template<> ::flyteidl::plugins::SparkJob_HadoopConfEntry_DoNotUse* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkJob_HadoopConfEntry_DoNotUse>(Arena*);
template<> ::flyteidl::plugins::SparkJob_SparkConfEntry_DoNotUse* Arena::CreateMaybeMessage<::flyteidl::plugins::SparkJob_SparkConfEntry_DoNotUse>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace flyteidl {
namespace plugins {

enum SparkApplication_Type {
  SparkApplication_Type_PYTHON = 0,
  SparkApplication_Type_JAVA = 1,
  SparkApplication_Type_SCALA = 2,
  SparkApplication_Type_R = 3,
  SparkApplication_Type_SparkApplication_Type_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits<::google::protobuf::int32>::min(),
  SparkApplication_Type_SparkApplication_Type_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits<::google::protobuf::int32>::max()
};
bool SparkApplication_Type_IsValid(int value);
const SparkApplication_Type SparkApplication_Type_Type_MIN = SparkApplication_Type_PYTHON;
const SparkApplication_Type SparkApplication_Type_Type_MAX = SparkApplication_Type_R;
const int SparkApplication_Type_Type_ARRAYSIZE = SparkApplication_Type_Type_MAX + 1;

const ::google::protobuf::EnumDescriptor* SparkApplication_Type_descriptor();
inline const ::std::string& SparkApplication_Type_Name(SparkApplication_Type value) {
  return ::google::protobuf::internal::NameOfEnum(
    SparkApplication_Type_descriptor(), value);
}
inline bool SparkApplication_Type_Parse(
    const ::std::string& name, SparkApplication_Type* value) {
  return ::google::protobuf::internal::ParseNamedEnum<SparkApplication_Type>(
    SparkApplication_Type_descriptor(), name, value);
}
// ===================================================================

class SparkApplication final :
    public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:flyteidl.plugins.SparkApplication) */ {
 public:
  SparkApplication();
  virtual ~SparkApplication();

  SparkApplication(const SparkApplication& from);

  inline SparkApplication& operator=(const SparkApplication& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SparkApplication(SparkApplication&& from) noexcept
    : SparkApplication() {
    *this = ::std::move(from);
  }

  inline SparkApplication& operator=(SparkApplication&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor() {
    return default_instance().GetDescriptor();
  }
  static const SparkApplication& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SparkApplication* internal_default_instance() {
    return reinterpret_cast<const SparkApplication*>(
               &_SparkApplication_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(SparkApplication* other);
  friend void swap(SparkApplication& a, SparkApplication& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SparkApplication* New() const final {
    return CreateMaybeMessage<SparkApplication>(nullptr);
  }

  SparkApplication* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SparkApplication>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SparkApplication& from);
  void MergeFrom(const SparkApplication& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  static const char* _InternalParse(const char* begin, const char* end, void* object, ::google::protobuf::internal::ParseContext* ctx);
  ::google::protobuf::internal::ParseFunc _ParseFunc() const final { return _InternalParse; }
  #else
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SparkApplication* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef SparkApplication_Type Type;
  static const Type PYTHON =
    SparkApplication_Type_PYTHON;
  static const Type JAVA =
    SparkApplication_Type_JAVA;
  static const Type SCALA =
    SparkApplication_Type_SCALA;
  static const Type R =
    SparkApplication_Type_R;
  static inline bool Type_IsValid(int value) {
    return SparkApplication_Type_IsValid(value);
  }
  static const Type Type_MIN =
    SparkApplication_Type_Type_MIN;
  static const Type Type_MAX =
    SparkApplication_Type_Type_MAX;
  static const int Type_ARRAYSIZE =
    SparkApplication_Type_Type_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  Type_descriptor() {
    return SparkApplication_Type_descriptor();
  }
  static inline const ::std::string& Type_Name(Type value) {
    return SparkApplication_Type_Name(value);
  }
  static inline bool Type_Parse(const ::std::string& name,
      Type* value) {
    return SparkApplication_Type_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:flyteidl.plugins.SparkApplication)
 private:
  class HasBitSetters;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_flyteidl_2fplugins_2fspark_2eproto;
};
// -------------------------------------------------------------------

class SparkJob_SparkConfEntry_DoNotUse : public ::google::protobuf::internal::MapEntry<SparkJob_SparkConfEntry_DoNotUse, 
    ::std::string, ::std::string,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    0 > {
public:
#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
static bool _ParseMap(const char* begin, const char* end, void* object, ::google::protobuf::internal::ParseContext* ctx);
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  typedef ::google::protobuf::internal::MapEntry<SparkJob_SparkConfEntry_DoNotUse, 
    ::std::string, ::std::string,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    0 > SuperType;
  SparkJob_SparkConfEntry_DoNotUse();
  SparkJob_SparkConfEntry_DoNotUse(::google::protobuf::Arena* arena);
  void MergeFrom(const SparkJob_SparkConfEntry_DoNotUse& other);
  static const SparkJob_SparkConfEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const SparkJob_SparkConfEntry_DoNotUse*>(&_SparkJob_SparkConfEntry_DoNotUse_default_instance_); }
  void MergeFrom(const ::google::protobuf::Message& other) final;
  ::google::protobuf::Metadata GetMetadata() const;
};

// -------------------------------------------------------------------

class SparkJob_HadoopConfEntry_DoNotUse : public ::google::protobuf::internal::MapEntry<SparkJob_HadoopConfEntry_DoNotUse, 
    ::std::string, ::std::string,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    0 > {
public:
#if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
static bool _ParseMap(const char* begin, const char* end, void* object, ::google::protobuf::internal::ParseContext* ctx);
#endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  typedef ::google::protobuf::internal::MapEntry<SparkJob_HadoopConfEntry_DoNotUse, 
    ::std::string, ::std::string,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
    0 > SuperType;
  SparkJob_HadoopConfEntry_DoNotUse();
  SparkJob_HadoopConfEntry_DoNotUse(::google::protobuf::Arena* arena);
  void MergeFrom(const SparkJob_HadoopConfEntry_DoNotUse& other);
  static const SparkJob_HadoopConfEntry_DoNotUse* internal_default_instance() { return reinterpret_cast<const SparkJob_HadoopConfEntry_DoNotUse*>(&_SparkJob_HadoopConfEntry_DoNotUse_default_instance_); }
  void MergeFrom(const ::google::protobuf::Message& other) final;
  ::google::protobuf::Metadata GetMetadata() const;
};

// -------------------------------------------------------------------

class SparkJob final :
    public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:flyteidl.plugins.SparkJob) */ {
 public:
  SparkJob();
  virtual ~SparkJob();

  SparkJob(const SparkJob& from);

  inline SparkJob& operator=(const SparkJob& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SparkJob(SparkJob&& from) noexcept
    : SparkJob() {
    *this = ::std::move(from);
  }

  inline SparkJob& operator=(SparkJob&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  static const ::google::protobuf::Descriptor* descriptor() {
    return default_instance().GetDescriptor();
  }
  static const SparkJob& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SparkJob* internal_default_instance() {
    return reinterpret_cast<const SparkJob*>(
               &_SparkJob_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  void Swap(SparkJob* other);
  friend void swap(SparkJob& a, SparkJob& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SparkJob* New() const final {
    return CreateMaybeMessage<SparkJob>(nullptr);
  }

  SparkJob* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SparkJob>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SparkJob& from);
  void MergeFrom(const SparkJob& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  #if GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  static const char* _InternalParse(const char* begin, const char* end, void* object, ::google::protobuf::internal::ParseContext* ctx);
  ::google::protobuf::internal::ParseFunc _ParseFunc() const final { return _InternalParse; }
  #else
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  #endif  // GOOGLE_PROTOBUF_ENABLE_EXPERIMENTAL_PARSER
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SparkJob* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return nullptr;
  }
  inline void* MaybeArenaPtr() const {
    return nullptr;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------


  // accessors -------------------------------------------------------

  // map<string, string> sparkConf = 4;
  int sparkconf_size() const;
  void clear_sparkconf();
  static const int kSparkConfFieldNumber = 4;
  const ::google::protobuf::Map< ::std::string, ::std::string >&
      sparkconf() const;
  ::google::protobuf::Map< ::std::string, ::std::string >*
      mutable_sparkconf();

  // map<string, string> hadoopConf = 5;
  int hadoopconf_size() const;
  void clear_hadoopconf();
  static const int kHadoopConfFieldNumber = 5;
  const ::google::protobuf::Map< ::std::string, ::std::string >&
      hadoopconf() const;
  ::google::protobuf::Map< ::std::string, ::std::string >*
      mutable_hadoopconf();

  // string mainApplicationFile = 2;
  void clear_mainapplicationfile();
  static const int kMainApplicationFileFieldNumber = 2;
  const ::std::string& mainapplicationfile() const;
  void set_mainapplicationfile(const ::std::string& value);
  #if LANG_CXX11
  void set_mainapplicationfile(::std::string&& value);
  #endif
  void set_mainapplicationfile(const char* value);
  void set_mainapplicationfile(const char* value, size_t size);
  ::std::string* mutable_mainapplicationfile();
  ::std::string* release_mainapplicationfile();
  void set_allocated_mainapplicationfile(::std::string* mainapplicationfile);

  // string mainClass = 3;
  void clear_mainclass();
  static const int kMainClassFieldNumber = 3;
  const ::std::string& mainclass() const;
  void set_mainclass(const ::std::string& value);
  #if LANG_CXX11
  void set_mainclass(::std::string&& value);
  #endif
  void set_mainclass(const char* value);
  void set_mainclass(const char* value, size_t size);
  ::std::string* mutable_mainclass();
  ::std::string* release_mainclass();
  void set_allocated_mainclass(::std::string* mainclass);

  // string executorPath = 6;
  void clear_executorpath();
  static const int kExecutorPathFieldNumber = 6;
  const ::std::string& executorpath() const;
  void set_executorpath(const ::std::string& value);
  #if LANG_CXX11
  void set_executorpath(::std::string&& value);
  #endif
  void set_executorpath(const char* value);
  void set_executorpath(const char* value, size_t size);
  ::std::string* mutable_executorpath();
  ::std::string* release_executorpath();
  void set_allocated_executorpath(::std::string* executorpath);

  // string databricksToken = 8;
  void clear_databrickstoken();
  static const int kDatabricksTokenFieldNumber = 8;
  const ::std::string& databrickstoken() const;
  void set_databrickstoken(const ::std::string& value);
  #if LANG_CXX11
  void set_databrickstoken(::std::string&& value);
  #endif
  void set_databrickstoken(const char* value);
  void set_databrickstoken(const char* value, size_t size);
  ::std::string* mutable_databrickstoken();
  ::std::string* release_databrickstoken();
  void set_allocated_databrickstoken(::std::string* databrickstoken);

  // string databricksInstance = 9;
  void clear_databricksinstance();
  static const int kDatabricksInstanceFieldNumber = 9;
  const ::std::string& databricksinstance() const;
  void set_databricksinstance(const ::std::string& value);
  #if LANG_CXX11
  void set_databricksinstance(::std::string&& value);
  #endif
  void set_databricksinstance(const char* value);
  void set_databricksinstance(const char* value, size_t size);
  ::std::string* mutable_databricksinstance();
  ::std::string* release_databricksinstance();
  void set_allocated_databricksinstance(::std::string* databricksinstance);

  // .google.protobuf.Struct databricksConf = 7;
  bool has_databricksconf() const;
  void clear_databricksconf();
  static const int kDatabricksConfFieldNumber = 7;
  const ::google::protobuf::Struct& databricksconf() const;
  ::google::protobuf::Struct* release_databricksconf();
  ::google::protobuf::Struct* mutable_databricksconf();
  void set_allocated_databricksconf(::google::protobuf::Struct* databricksconf);

  // .flyteidl.plugins.SparkApplication.Type applicationType = 1;
  void clear_applicationtype();
  static const int kApplicationTypeFieldNumber = 1;
  ::flyteidl::plugins::SparkApplication_Type applicationtype() const;
  void set_applicationtype(::flyteidl::plugins::SparkApplication_Type value);

  // @@protoc_insertion_point(class_scope:flyteidl.plugins.SparkJob)
 private:
  class HasBitSetters;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::MapField<
      SparkJob_SparkConfEntry_DoNotUse,
      ::std::string, ::std::string,
      ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
      ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
      0 > sparkconf_;
  ::google::protobuf::internal::MapField<
      SparkJob_HadoopConfEntry_DoNotUse,
      ::std::string, ::std::string,
      ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
      ::google::protobuf::internal::WireFormatLite::TYPE_STRING,
      0 > hadoopconf_;
  ::google::protobuf::internal::ArenaStringPtr mainapplicationfile_;
  ::google::protobuf::internal::ArenaStringPtr mainclass_;
  ::google::protobuf::internal::ArenaStringPtr executorpath_;
  ::google::protobuf::internal::ArenaStringPtr databrickstoken_;
  ::google::protobuf::internal::ArenaStringPtr databricksinstance_;
  ::google::protobuf::Struct* databricksconf_;
  int applicationtype_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::TableStruct_flyteidl_2fplugins_2fspark_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// SparkApplication

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// SparkJob

// .flyteidl.plugins.SparkApplication.Type applicationType = 1;
inline void SparkJob::clear_applicationtype() {
  applicationtype_ = 0;
}
inline ::flyteidl::plugins::SparkApplication_Type SparkJob::applicationtype() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.applicationType)
  return static_cast< ::flyteidl::plugins::SparkApplication_Type >(applicationtype_);
}
inline void SparkJob::set_applicationtype(::flyteidl::plugins::SparkApplication_Type value) {
  
  applicationtype_ = value;
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.applicationType)
}

// string mainApplicationFile = 2;
inline void SparkJob::clear_mainapplicationfile() {
  mainapplicationfile_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SparkJob::mainapplicationfile() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.mainApplicationFile)
  return mainapplicationfile_.GetNoArena();
}
inline void SparkJob::set_mainapplicationfile(const ::std::string& value) {
  
  mainapplicationfile_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.mainApplicationFile)
}
#if LANG_CXX11
inline void SparkJob::set_mainapplicationfile(::std::string&& value) {
  
  mainapplicationfile_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:flyteidl.plugins.SparkJob.mainApplicationFile)
}
#endif
inline void SparkJob::set_mainapplicationfile(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  mainapplicationfile_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:flyteidl.plugins.SparkJob.mainApplicationFile)
}
inline void SparkJob::set_mainapplicationfile(const char* value, size_t size) {
  
  mainapplicationfile_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:flyteidl.plugins.SparkJob.mainApplicationFile)
}
inline ::std::string* SparkJob::mutable_mainapplicationfile() {
  
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.mainApplicationFile)
  return mainapplicationfile_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SparkJob::release_mainapplicationfile() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.mainApplicationFile)
  
  return mainapplicationfile_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SparkJob::set_allocated_mainapplicationfile(::std::string* mainapplicationfile) {
  if (mainapplicationfile != nullptr) {
    
  } else {
    
  }
  mainapplicationfile_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), mainapplicationfile);
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.mainApplicationFile)
}

// string mainClass = 3;
inline void SparkJob::clear_mainclass() {
  mainclass_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SparkJob::mainclass() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.mainClass)
  return mainclass_.GetNoArena();
}
inline void SparkJob::set_mainclass(const ::std::string& value) {
  
  mainclass_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.mainClass)
}
#if LANG_CXX11
inline void SparkJob::set_mainclass(::std::string&& value) {
  
  mainclass_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:flyteidl.plugins.SparkJob.mainClass)
}
#endif
inline void SparkJob::set_mainclass(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  mainclass_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:flyteidl.plugins.SparkJob.mainClass)
}
inline void SparkJob::set_mainclass(const char* value, size_t size) {
  
  mainclass_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:flyteidl.plugins.SparkJob.mainClass)
}
inline ::std::string* SparkJob::mutable_mainclass() {
  
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.mainClass)
  return mainclass_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SparkJob::release_mainclass() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.mainClass)
  
  return mainclass_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SparkJob::set_allocated_mainclass(::std::string* mainclass) {
  if (mainclass != nullptr) {
    
  } else {
    
  }
  mainclass_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), mainclass);
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.mainClass)
}

// map<string, string> sparkConf = 4;
inline int SparkJob::sparkconf_size() const {
  return sparkconf_.size();
}
inline void SparkJob::clear_sparkconf() {
  sparkconf_.Clear();
}
inline const ::google::protobuf::Map< ::std::string, ::std::string >&
SparkJob::sparkconf() const {
  // @@protoc_insertion_point(field_map:flyteidl.plugins.SparkJob.sparkConf)
  return sparkconf_.GetMap();
}
inline ::google::protobuf::Map< ::std::string, ::std::string >*
SparkJob::mutable_sparkconf() {
  // @@protoc_insertion_point(field_mutable_map:flyteidl.plugins.SparkJob.sparkConf)
  return sparkconf_.MutableMap();
}

// map<string, string> hadoopConf = 5;
inline int SparkJob::hadoopconf_size() const {
  return hadoopconf_.size();
}
inline void SparkJob::clear_hadoopconf() {
  hadoopconf_.Clear();
}
inline const ::google::protobuf::Map< ::std::string, ::std::string >&
SparkJob::hadoopconf() const {
  // @@protoc_insertion_point(field_map:flyteidl.plugins.SparkJob.hadoopConf)
  return hadoopconf_.GetMap();
}
inline ::google::protobuf::Map< ::std::string, ::std::string >*
SparkJob::mutable_hadoopconf() {
  // @@protoc_insertion_point(field_mutable_map:flyteidl.plugins.SparkJob.hadoopConf)
  return hadoopconf_.MutableMap();
}

// string executorPath = 6;
inline void SparkJob::clear_executorpath() {
  executorpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SparkJob::executorpath() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.executorPath)
  return executorpath_.GetNoArena();
}
inline void SparkJob::set_executorpath(const ::std::string& value) {
  
  executorpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.executorPath)
}
#if LANG_CXX11
inline void SparkJob::set_executorpath(::std::string&& value) {
  
  executorpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:flyteidl.plugins.SparkJob.executorPath)
}
#endif
inline void SparkJob::set_executorpath(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  executorpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:flyteidl.plugins.SparkJob.executorPath)
}
inline void SparkJob::set_executorpath(const char* value, size_t size) {
  
  executorpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:flyteidl.plugins.SparkJob.executorPath)
}
inline ::std::string* SparkJob::mutable_executorpath() {
  
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.executorPath)
  return executorpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SparkJob::release_executorpath() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.executorPath)
  
  return executorpath_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SparkJob::set_allocated_executorpath(::std::string* executorpath) {
  if (executorpath != nullptr) {
    
  } else {
    
  }
  executorpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), executorpath);
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.executorPath)
}

// .google.protobuf.Struct databricksConf = 7;
inline bool SparkJob::has_databricksconf() const {
  return this != internal_default_instance() && databricksconf_ != nullptr;
}
inline const ::google::protobuf::Struct& SparkJob::databricksconf() const {
  const ::google::protobuf::Struct* p = databricksconf_;
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.databricksConf)
  return p != nullptr ? *p : *reinterpret_cast<const ::google::protobuf::Struct*>(
      &::google::protobuf::_Struct_default_instance_);
}
inline ::google::protobuf::Struct* SparkJob::release_databricksconf() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.databricksConf)
  
  ::google::protobuf::Struct* temp = databricksconf_;
  databricksconf_ = nullptr;
  return temp;
}
inline ::google::protobuf::Struct* SparkJob::mutable_databricksconf() {
  
  if (databricksconf_ == nullptr) {
    auto* p = CreateMaybeMessage<::google::protobuf::Struct>(GetArenaNoVirtual());
    databricksconf_ = p;
  }
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.databricksConf)
  return databricksconf_;
}
inline void SparkJob::set_allocated_databricksconf(::google::protobuf::Struct* databricksconf) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == nullptr) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(databricksconf_);
  }
  if (databricksconf) {
    ::google::protobuf::Arena* submessage_arena =
      reinterpret_cast<::google::protobuf::MessageLite*>(databricksconf)->GetArena();
    if (message_arena != submessage_arena) {
      databricksconf = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, databricksconf, submessage_arena);
    }
    
  } else {
    
  }
  databricksconf_ = databricksconf;
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.databricksConf)
}

// string databricksToken = 8;
inline void SparkJob::clear_databrickstoken() {
  databrickstoken_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SparkJob::databrickstoken() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.databricksToken)
  return databrickstoken_.GetNoArena();
}
inline void SparkJob::set_databrickstoken(const ::std::string& value) {
  
  databrickstoken_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.databricksToken)
}
#if LANG_CXX11
inline void SparkJob::set_databrickstoken(::std::string&& value) {
  
  databrickstoken_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:flyteidl.plugins.SparkJob.databricksToken)
}
#endif
inline void SparkJob::set_databrickstoken(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  databrickstoken_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:flyteidl.plugins.SparkJob.databricksToken)
}
inline void SparkJob::set_databrickstoken(const char* value, size_t size) {
  
  databrickstoken_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:flyteidl.plugins.SparkJob.databricksToken)
}
inline ::std::string* SparkJob::mutable_databrickstoken() {
  
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.databricksToken)
  return databrickstoken_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SparkJob::release_databrickstoken() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.databricksToken)
  
  return databrickstoken_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SparkJob::set_allocated_databrickstoken(::std::string* databrickstoken) {
  if (databrickstoken != nullptr) {
    
  } else {
    
  }
  databrickstoken_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), databrickstoken);
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.databricksToken)
}

// string databricksInstance = 9;
inline void SparkJob::clear_databricksinstance() {
  databricksinstance_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline const ::std::string& SparkJob::databricksinstance() const {
  // @@protoc_insertion_point(field_get:flyteidl.plugins.SparkJob.databricksInstance)
  return databricksinstance_.GetNoArena();
}
inline void SparkJob::set_databricksinstance(const ::std::string& value) {
  
  databricksinstance_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:flyteidl.plugins.SparkJob.databricksInstance)
}
#if LANG_CXX11
inline void SparkJob::set_databricksinstance(::std::string&& value) {
  
  databricksinstance_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:flyteidl.plugins.SparkJob.databricksInstance)
}
#endif
inline void SparkJob::set_databricksinstance(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  
  databricksinstance_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:flyteidl.plugins.SparkJob.databricksInstance)
}
inline void SparkJob::set_databricksinstance(const char* value, size_t size) {
  
  databricksinstance_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:flyteidl.plugins.SparkJob.databricksInstance)
}
inline ::std::string* SparkJob::mutable_databricksinstance() {
  
  // @@protoc_insertion_point(field_mutable:flyteidl.plugins.SparkJob.databricksInstance)
  return databricksinstance_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SparkJob::release_databricksinstance() {
  // @@protoc_insertion_point(field_release:flyteidl.plugins.SparkJob.databricksInstance)
  
  return databricksinstance_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SparkJob::set_allocated_databricksinstance(::std::string* databricksinstance) {
  if (databricksinstance != nullptr) {
    
  } else {
    
  }
  databricksinstance_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), databricksinstance);
  // @@protoc_insertion_point(field_set_allocated:flyteidl.plugins.SparkJob.databricksInstance)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace plugins
}  // namespace flyteidl

namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::flyteidl::plugins::SparkApplication_Type> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::flyteidl::plugins::SparkApplication_Type>() {
  return ::flyteidl::plugins::SparkApplication_Type_descriptor();
}

}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // PROTOBUF_INCLUDED_flyteidl_2fplugins_2fspark_2eproto
